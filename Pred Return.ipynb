{"cells":[{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2025-05-06T22:42:09.792463Z","iopub.status.busy":"2025-05-06T22:42:09.792172Z","iopub.status.idle":"2025-05-06T22:42:09.809729Z","shell.execute_reply":"2025-05-06T22:42:09.808819Z","shell.execute_reply.started":"2025-05-06T22:42:09.792443Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import EarlyStopping"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2025-05-06T22:47:27.800485Z","iopub.status.busy":"2025-05-06T22:47:27.799912Z","iopub.status.idle":"2025-05-06T22:47:27.845101Z","shell.execute_reply":"2025-05-06T22:47:27.844416Z","shell.execute_reply.started":"2025-05-06T22:47:27.800460Z"},"trusted":true},"outputs":[],"source":["df = pd.read_stata(\"/kaggle/input/d/rupsha137/mutual-funds/net_f_2.dta\")"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2025-05-06T22:47:28.541645Z","iopub.status.busy":"2025-05-06T22:47:28.541071Z","iopub.status.idle":"2025-05-06T22:47:28.566700Z","shell.execute_reply":"2025-05-06T22:47:28.565964Z","shell.execute_reply.started":"2025-05-06T22:47:28.541619Z"},"trusted":true},"outputs":[{"data":{"text/plain":["2906"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["df = df.dropna()\n","df = df[df[\"ann_net_sortino\"] <= 10]\n","df = df[df[\"ann_net_sharpe_ratio\"] <= 5.5]\n","df['a1'].nunique()"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2025-05-06T22:47:29.097536Z","iopub.status.busy":"2025-05-06T22:47:29.097246Z","iopub.status.idle":"2025-05-06T22:47:29.103752Z","shell.execute_reply":"2025-05-06T22:47:29.103110Z","shell.execute_reply.started":"2025-05-06T22:47:29.097517Z"},"trusted":true},"outputs":[],"source":["columns_to_drop = [\n","    'net_st_info_ratio',\n","    'net_st_tracking_error',\n","    'gross_st_tracking_error',\n","    'gross_mk_tracking_error',\n","    'gross_st_info_ratio',\n","    'gross_mk_info_ratio',\n","    'ann_gross_sharpe_ratio',\n","    'ann_gross_sortino','obj1'\n","]\n","\n","df = df.drop(columns=columns_to_drop)"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2025-05-06T22:47:31.625812Z","iopub.status.busy":"2025-05-06T22:47:31.625538Z","iopub.status.idle":"2025-05-06T22:47:31.654696Z","shell.execute_reply":"2025-05-06T22:47:31.653978Z","shell.execute_reply.started":"2025-05-06T22:47:31.625793Z"},"trusted":true},"outputs":[],"source":["# Normalize features\n","feature_cols = [col for col in df.columns if col not in [\"a1\", \"y\", \"ann_net_rf_ret\"]]\n","scaler = StandardScaler()\n","df[feature_cols] = scaler.fit_transform(df[feature_cols])"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2025-05-06T22:47:35.940220Z","iopub.status.busy":"2025-05-06T22:47:35.939876Z","iopub.status.idle":"2025-05-06T22:47:37.539479Z","shell.execute_reply":"2025-05-06T22:47:37.536491Z","shell.execute_reply.started":"2025-05-06T22:47:35.940194Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n","\n","\n","ols_preds = []\n","performance = []\n","ols_importance = []\n","\n","for target_year in range(2005, 2022):\n","    train_years = list(range(target_year - 10, target_year))\n","    test_year = target_year\n","\n","    train_data = df[df['y'].isin(train_years)]\n","    test_data = df[df['y'] == test_year]\n","\n","    if train_data.empty or test_data.empty:\n","        continue\n","\n","    X_train = train_data[feature_cols]\n","    y_train = train_data[\"ann_net_rf_ret\"]\n","    X_test = test_data[feature_cols]\n","    y_test = test_data[\"ann_net_rf_ret\"]\n","    fund_test = test_data[\"a1\"]\n","\n","    # Fit model\n","    ols = LinearRegression()\n","    ols.fit(X_train, y_train)\n","    preds = ols.predict(X_test)\n","\n","    # Store predictions\n","    for i in range(len(preds)):\n","        ols_preds.append({\n","            'a1': fund_test.iloc[i],\n","            'year': test_year,\n","            'actual_value': y_test.iloc[i],\n","            'predicted_value': preds[i],\n","            'model': 'OLS'\n","        })\n","\n","    # Store performance\n","    performance.append({\n","        'model': 'OLS',\n","        'year': test_year,\n","        'r2': r2_score(y_test, preds),\n","        'rmse': mean_squared_error(y_test, preds, squared=False),\n","        'mae': mean_absolute_error(y_test, preds)\n","    })\n","\n","    # Store coefficient importance\n","    for i, col in enumerate(feature_cols):\n","        ols_importance.append({\n","            'model': 'OLS',\n","            'predictor': col,\n","            'importance': ols.coef_[i],\n","            'year': test_year\n","        })\n","\n","# ---- Convert to DataFrames ----\n","ols_preds_df = pd.DataFrame(ols_preds)\n","ols_perf_df = pd.DataFrame(performance)\n","ols_imp_df = pd.DataFrame(ols_importance)\n","\n","ols_preds_df.to_csv(\"/kaggle/working/ols_predictions.csv\", index=False)\n","ols_perf_df.to_csv(\"/kaggle/working/ols_performance.csv\", index=False)\n","ols_imp_df.to_csv(\"/kaggle/working/ols_feature_importance.csv\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","\n","os.remove(\"/kaggle/working/ols_predictions.csv\")\n","os.remove(\"/kaggle/working/ols_performance.csv\")\n","os.remove(\"/kaggle/working/ols_feature_importance.csv\")"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2025-05-06T22:49:44.937777Z","iopub.status.busy":"2025-05-06T22:49:44.937140Z","iopub.status.idle":"2025-05-06T22:49:44.941738Z","shell.execute_reply":"2025-05-06T22:49:44.940773Z","shell.execute_reply.started":"2025-05-06T22:49:44.937753Z"},"trusted":true},"outputs":[],"source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2025-05-06T22:49:54.942843Z","iopub.status.busy":"2025-05-06T22:49:54.942551Z","iopub.status.idle":"2025-05-06T22:54:28.969853Z","shell.execute_reply":"2025-05-06T22:54:28.968735Z","shell.execute_reply.started":"2025-05-06T22:49:54.942820Z"},"trusted":true},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/275570373.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Fit Random Forest model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","\n","# Replace the following as needed\n","# df = ... # your DataFrame\n","# feature_cols = [...] # your list of feature column names\n","\n","rf_preds = []\n","performance = []\n","rf_importance = []\n","\n","for target_year in range(2005, 2022):\n","    train_years = list(range(target_year - 10, target_year))\n","    test_year = target_year\n","\n","    train_data = df[df['y'].isin(train_years)]\n","    test_data = df[df['y'] == test_year]\n","\n","    if train_data.empty or test_data.empty:\n","        continue\n","\n","    X_train = train_data[feature_cols]\n","    y_train = train_data[\"ann_net_rf_ret\"]\n","    X_test = test_data[feature_cols]\n","    y_test = test_data[\"ann_net_rf_ret\"]\n","    fund_test = test_data[\"a1\"]\n","\n","    # Fit Random Forest model\n","    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n","    rf.fit(X_train, y_train)\n","    preds = rf.predict(X_test)\n","\n","    # Store predictions\n","    for i in range(len(preds)):\n","        rf_preds.append({\n","            'a1': fund_test.iloc[i],\n","            'year': test_year,\n","            'actual_value': y_test.iloc[i],\n","            'predicted_value': preds[i],\n","            'model': 'RandomForest'\n","        })\n","\n","    # Store performance\n","    performance.append({\n","        'model': 'RandomForest',\n","        'year': test_year,\n","        'r2': r2_score(y_test, preds),\n","        'rmse': mean_squared_error(y_test, preds, squared=False),\n","        'mae': mean_absolute_error(y_test, preds)\n","    })\n","\n","    # Store feature importances\n","    importances = rf.feature_importances_\n","    for i, col in enumerate(feature_cols):\n","        rf_importance.append({\n","            'model': 'RandomForest',\n","            'predictor': col,\n","            'importance': importances[i],\n","            'year': test_year\n","        })\n","\n","# ---- Convert to DataFrames ----\n","rf_preds_df = pd.DataFrame(rf_preds)\n","rf_perf_df = pd.DataFrame(performance)\n","rf_imp_df = pd.DataFrame(rf_importance)\n","\n","# Save to CSV\n","rf_preds_df.to_csv(\"/kaggle/working/rf_predictions.csv\", index=False)\n","rf_perf_df.to_csv(\"/kaggle/working/rf_performance.csv\", index=False)\n","rf_imp_df.to_csv(\"/kaggle/working/rf_feature_importance.csv\", index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-05-06T22:42:10.698749Z","iopub.status.idle":"2025-05-06T22:42:10.699024Z","shell.execute_reply":"2025-05-06T22:42:10.698895Z","shell.execute_reply.started":"2025-05-06T22:42:10.698883Z"},"trusted":true},"outputs":[],"source":["# ---- Initialize Lists ----\n","rf_preds = []\n","rf_perf = []\n","rf_importance = []\n","\n","# ---- Hyperparameter Search Space ----\n","param_dist = {\n","    'n_estimators': randint(100, 200),\n","    'max_depth': randint(3, 20),\n","    'min_samples_split': randint(2, 10),\n","    'min_samples_leaf': randint(1, 5),\n","    'max_features': ['auto', 'sqrt', 'log2']\n","}\n","\n","# ---- Loop Over Years ----\n","for target_year in range(2005, 2022):\n","    train_years = list(range(target_year - 10, target_year))\n","    test_year = target_year\n","\n","    train_data = df[df['y'].isin(train_years)]\n","    test_data = df[df['y'] == test_year]\n","\n","    if train_data.empty or test_data.empty:\n","        continue\n","\n","    X_train = train_data[feature_cols]\n","    y_train = train_data[\"ann_net_rf_ret\"]\n","    X_test = test_data[feature_cols]\n","    y_test = test_data[\"ann_net_rf_ret\"]\n","    fund_test = test_data[\"a1\"]\n","\n","    # ---- Hyperparameter Tuning ----\n","    base_rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n","    random_search = RandomizedSearchCV(\n","        base_rf,\n","        param_distributions=param_dist,\n","        n_iter=20,\n","        scoring='neg_mean_squared_error',\n","        cv=3,\n","        n_jobs=-1,\n","        random_state=42\n","    )\n","    random_search.fit(X_train, y_train)\n","    best_rf = random_search.best_estimator_\n","\n","    # ---- Fit and Predict ----\n","    preds = best_rf.predict(X_test)\n","\n","    # Store predictions\n","    for i in range(len(preds)):\n","        rf_preds.append({\n","            'a1': fund_test.iloc[i],\n","            'year': test_year,\n","            'actual_value': y_test.iloc[i],\n","            'predicted_value': preds[i],\n","            'model': 'Random Forest'\n","        })\n","\n","    # Store performance\n","    rf_perf.append({\n","        'model': 'Random Forest',\n","        'year': test_year,\n","        'r2': r2_score(y_test, preds),\n","        'rmse': np.sqrt(mean_squared_error(y_test, preds)),\n","        'mae': mean_absolute_error(y_test, preds)\n","    })\n","\n","    # Store feature importance\n","    for i, col in enumerate(feature_cols):\n","        rf_importance.append({\n","            'model': 'Random Forest',\n","            'predictor': col,\n","            'importance': best_rf.feature_importances_[i],\n","            'year': test_year\n","        })\n","\n","    # ---- Progress Log ----\n","    print(f\"âœ… Completed Random Forest for year: {test_year}\")\n","\n","# ---- Convert to DataFrames ----\n","rf_preds_df = pd.DataFrame(rf_preds)\n","rf_perf_df = pd.DataFrame(rf_perf)\n","rf_imp_df = pd.DataFrame(rf_importance)\n","\n","# ---- Save to CSV ----\n","rf_preds_df.to_csv(\"/kaggle/working/rf_predictions.csv\", index=False)\n","rf_perf_df.to_csv(\"/kaggle/working/rf_performance.csv\", index=False)\n","rf_imp_df.to_csv(\"/kaggle/working/rf_feature_importance.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-05-06T22:42:10.701925Z","iopub.status.idle":"2025-05-06T22:42:10.702300Z","shell.execute_reply":"2025-05-06T22:42:10.702135Z","shell.execute_reply.started":"2025-05-06T22:42:10.702120Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n","from scipy.stats import randint, uniform\n","\n","gb_preds = []\n","gb_perf = []\n","gb_importance = []\n","\n","# ---- Broad Param Distribution for RandomizedSearchCV ----\n","param_dist = {\n","    'n_estimators': randint(50, 150),\n","    'max_depth': randint(3, 7),\n","    'learning_rate': uniform(0.03, 0.1),\n","    'subsample': uniform(0.7, 0.3)\n","}\n","\n","# ---- Loop Over Years ----\n","for target_year in range(2005, 2022):\n","    train_years = list(range(target_year - 10, target_year))\n","    test_year = target_year\n","\n","    train_data = df[df['y'].isin(train_years)]\n","    test_data = df[df['y'] == test_year]\n","\n","    if train_data.empty or test_data.empty:\n","        continue\n","\n","    X_train = train_data[feature_cols]\n","    y_train = train_data[\"ann_net_rf_ret\"]\n","    X_test = test_data[feature_cols]\n","    y_test = test_data[\"ann_net_rf_ret\"]\n","    fund_test = test_data[\"a1\"]\n","\n","    # ---- Randomized Search (Broad) ----\n","    base_gb = GradientBoostingRegressor(random_state=42)\n","    rand_search = RandomizedSearchCV(\n","        estimator=base_gb,\n","        param_distributions=param_dist,\n","        n_iter=10,\n","        cv=3,\n","        scoring='neg_mean_squared_error',\n","        n_jobs=-1,\n","        random_state=42\n","    )\n","    rand_search.fit(X_train, y_train)\n","\n","    # ---- Narrow Grid Search (Fine-Tuning) ----\n","    best_params = rand_search.best_params_\n","\n","    grid_param = {\n","        'n_estimators': [max(50, best_params['n_estimators'] - 20), best_params['n_estimators'], best_params['n_estimators'] + 20],\n","        'max_depth': [max(1, best_params['max_depth'] - 1), best_params['max_depth'], best_params['max_depth'] + 1],\n","        'learning_rate': [best_params['learning_rate'] * 0.8, best_params['learning_rate'], best_params['learning_rate'] * 1.2],\n","        'subsample': [max(0.6, best_params['subsample'] - 0.1), best_params['subsample'], min(1.0, best_params['subsample'] + 0.1)]\n","    }\n","\n","    grid_search = GridSearchCV(\n","        estimator=base_gb,\n","        param_grid=grid_param,\n","        cv=3,\n","        scoring='neg_mean_squared_error',\n","        n_jobs=-1\n","    )\n","    grid_search.fit(X_train, y_train)\n","    best_gb = grid_search.best_estimator_\n","\n","    # ---- Fit and Predict ----\n","    preds = best_gb.predict(X_test)\n","\n","    # Store predictions\n","    for i in range(len(preds)):\n","        gb_preds.append({\n","            'a1': fund_test.iloc[i],\n","            'year': test_year,\n","            'actual_value': y_test.iloc[i],\n","            'predicted_value': preds[i],\n","            'model': 'Gradient Boosting'\n","        })\n","\n","    # Store performance\n","    gb_perf.append({\n","        'model': 'Gradient Boosting',\n","        'year': test_year,\n","        'r2': r2_score(y_test, preds),\n","        'rmse': mean_squared_error(y_test, preds, squared=False),\n","        'mae': mean_absolute_error(y_test, preds)\n","    })\n","\n","    # Store feature importance\n","    for i, col in enumerate(feature_cols):\n","        gb_importance.append({\n","            'model': 'Gradient Boosting',\n","            'predictor': col,\n","            'importance': best_gb.feature_importances_[i],\n","            'year': test_year\n","        })\n","\n","# ---- Convert to DataFrames ----\n","gb_preds_df = pd.DataFrame(gb_preds)\n","gb_perf_df = pd.DataFrame(gb_perf)\n","gb_imp_df = pd.DataFrame(gb_importance)\n","\n","# ---- Save to CSV ----\n","gb_preds_df.to_csv(\"/kaggle/working/gb_predictions.csv\", index=False)\n","gb_perf_df.to_csv(\"/kaggle/working/gb_performance.csv\", index=False)\n","gb_imp_df.to_csv(\"/kaggle/working/gb_feature_importance.csv\", index=False)\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":7330190,"sourceId":11679017,"sourceType":"datasetVersion"},{"datasetId":7339084,"sourceId":11692799,"sourceType":"datasetVersion"},{"datasetId":7339192,"sourceId":11692961,"sourceType":"datasetVersion"},{"datasetId":7348300,"sourceId":11707334,"sourceType":"datasetVersion"}],"dockerImageVersionId":31012,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":4}
